This page is to show how to detect upstream healthy status
---------------------------------------

- [Service Discovery](#service-discovery)
- [Loadbalancing](#loadbalancing)
  - [Distributed Load Balancing](#distributed-load-balancing)
  - [Global Load Balancing](#global-load-balancing)
  - [Both Distributed and Global](#both-distributed-and-global)
- [Outlier Detection (Passive HealthCheck)](#outlier-detection-passive-healthcheck)
  - [Detected error Categories](#detected-error-categories)
  - [Ejection algorithm](#ejection-algorithm)
  - [Detection Mode](#detection-mode)
  - [Detection Type](#detection-type)
- [Active Healthcheck](#active-healthcheck)
  - [HTTP health checking filter](#http-health-checking-filter)
- [Transient failure](#transient-failure)


# Service Discovery
* Static (backend)
* Strict_DNS (Inter-Pod)
* Logical_DNS 
* Original destination (egress to external used by http2lb)
* EDS


# Loadbalancing

Load balancing is a way of distributing traffic between multiple hosts within a single upstream cluster in order to effectively make use of available resources. There are many different ways of accomplishing this, so Envoy provides several different load balancing strategies. At a high level, we can break these strategies into two categories: global load balancing and distributed load balancing.

## Distributed Load Balancing

Envoy itself determine how load should be distributed to the endpoints
* Active Health Checking
* Zone Aware routing
* Load balancingalgorithms
  * Wighted round robin
  * Weighted least requrest
  * Ring hash
  * Maglev
  * Random

## Global Load Balancing

 a single, global authority that decides how load should be distributed between hosts by priority, locality weight, endpoint weight and endpoint health.

## Both Distributed and Global

# Outlier Detection (Passive HealthCheck)

Outlier detection and ejection is the process of dynamically determining whether some number of hosts in an upstream cluster are performing unlike the others and removing them from the healthy load balancing set

Outlier detection is part of the cluster configuration and it needs filters to report errors, timeouts, and resets. Currently,

It is passive health checking w/o filter support:
* http router
* tcp proxy
* Redis proxy
* thrift proxy

## Detected error Categories
* Externally generated error
  * occur on the upstream server in response to the received request
  * 
* Locally originated error
  * generated by Envoy in response to an event which interrupted or prevented communication with the upstream host.
    * timeout
    * tcp reset
    * inability to connect to a specified port

## Ejection algorithm
* Runs inline (for example in the case of consecutive 5xx)
* 
* At a specify interval (for example in the case of periodic success rate)


## Detection Mode
* Default mode
  * split_external_local_origin_errors = false
* Split mode
  * split_external_local_origin_errors = true

## Detection Type

* "consecutive_5xx": {...} == Default 5
  * default mode: 
    * takes into account all generated errors: locally originated and externally originated (transaction) errors.
    * tcp proxy or redis proxy will internally map to HTTP 5xx code
  * split mode
    * takes into account only externally originated (transaction) errors, ignoring locally originated errors.
 
  If an upstream host returns some number of errors which are treated as consecutive 5xx type errors, it will be ejected

* "consecutive_gateway_failure": {...}, == default 5
  * default mode
    * takes into account a subset of 5xx errors, called “gateway errors” (502, 503 or 504 status code) and local origin failures, such as timeout, TCP reset etc
  * split mode
    * takes into account a subset of 5xx errors, called “gateway errors” (502, 503 or 504 status code) and is supported only by the http router.

  If an upstream host returns some number of consecutive “gateway errors” (502, 503 or 504 status code), it will be ejected.

* "consecutive_local_origin_failure": {...}, == default 5
  * Only split mode
    * takes into account only locally originated errors (timeout, reset, ICMP eeor etc).


* Success Rate
  * Success Rate based outlier detection aggregates success rate data from every host in a cluster.
  * Then at given intervals ejects hosts based on statistical outlier detection
  * "success_rate_minimum_hosts": {...},
  * "success_rate_request_volume": {...},
  * "success_rate_stdev_factor": {...},

* Failure Percentage 

  * Failure Percentage based outlier detection functions similarly to success rate detection, in that it relies on success rate data from each host in a cluster. However, rather than compare those values to the mean success rate of the cluster as a whole, they are compared to a flat user-configured threshold. This threshold is configured via the outlier_detection.failure_percentage_threshold field.
  * "failure_percentage_threshold": {...},
  * "failure_percentage_minimum_hosts": {...},
  * "failure_percentage_request_volume": {...},


* Detection Configuration
  * "interval": {...} = default 10s
  
    The time interval between ejection analysis sweeps
  
  * "base_ejection_time": {...} = default 30s
    * How long it is for a host to be ejected
    * The real time is equal to the base time multiplied by the number of times the host has been ejected and is capped by max_ejection_time.
  
  * "max_ejection_time": {...}, = default 300s
  * "max_ejection_time_jitter": {...} = default 0
  * "max_ejection_percent": {...},

  "enforcing_consecutive_5xx": {...},
  "enforcing_consecutive_gateway_failure": {...},
  "enforcing_success_rate": {...},
  "enforcing_consecutive_local_origin_failure": {...},
  "enforcing_local_origin_success_rate": {...},  
  "enforcing_failure_percentage": {...},
  "enforcing_failure_percentage_local_origin": {...},


# Active Healthcheck
Active health checking can be configured on a per upstream cluster basis

* HTTP
  * send an HTTP request to the upstream host. By default, it expects a 200 response if the host is healthy
  * The upstream host can return a non-expected or non-retriable status code (any non-200 code by default) if it wants to immediately notify downstream hosts to no longer forward traffic to it.
  
* gRPC: same like with HTTP
  
* L3/L4: send buffer bytes to upstream and expects the buffer byte to be echoed in the response if upstream is healthy
* Redis
* Thrift

## HTTP health checking filter
When an Envoy mesh is deployed with active health checking between clusters, a large amount of health checking traffic can be generated.

* No pass through: In this mode, the health check request is never passed to the local service. Envoy will respond with a 200 or a 503 depending on the current draining state of the server.

* No pass through, computed from upstream cluster health: In this mode, the health checking filter will return a 200 or a 503 depending on whether at least a specified percentage of the servers are available (healthy + degraded) in one or more upstream clusters. (If the Envoy server is in a draining state, though, it will respond with a 503 regardless of the upstream cluster health.)

* Pass through: In this mode, Envoy will pass every health check request to the local service. The service is expected to return a 200 or a 503 depending on its health state.

* Pass through with caching: In this mode, Envoy will pass health check requests to the local service, but then cache the result for some period of time. Subsequent health check requests will return the cached value up to the cache time. When the cache time is reached, the next health check request will be passed to the local service. 

# Transient failure
https://www.envoyproxy.io/docs/envoy/latest/faq/load_balancing/transient_failures#

* Circuit Breaking
* Retries

Automatic request retries is another method of ensuring service resilience. Request retries should typically be used to guard against transient failures. Envoy supports very rich set of configurable parameters that dictate what type of requests are retried, how many times the request should be retried, timeouts for retries, etc.

```json
{
  "retry_on": ..., # x-envoy-retry-on 
  "num_retries": {...},
  "per_try_timeout": {...},
  "per_try_idle_timeout": {...},
  "retry_priority": {...},
  "retry_host_predicate": [],
  "retry_options_predicates": [],
  "host_selection_retry_max_attempts": ...,
  "retriable_status_codes": [],
  "retry_back_off": {...},
  "rate_limited_retry_back_off": {...},
  "retriable_headers": [],
  "retriable_request_headers": []
}
```

  * retry_on
    * 5xx
      ```
      Envoy will attempt a retry if the upstream server responds with any 5xx response code, or does not respond at all (disconnect/reset/read timeout). (Includes connect-failure and refused-stream)
      ```
    * gateway-error: 502, 503, or 504.
    * reset: if the upstream server does not respond at all (disconnect/reset/read timeout.)
    * connect-failure
    * envoy-ratelimited
    * retriable-4xx
    * refused-steam
    * retriable-status-codes
    * retriable-headers
    * http3-post-connect-failure
  * dd
* Retries in gRPC services
* Outlier Detection

